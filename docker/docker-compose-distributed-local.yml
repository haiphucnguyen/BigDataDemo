version: "3"

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: namenode
    #volumes:
    #  - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    ports:
      - 8020:8020
      - 50070:50070

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode
    #volumes:
    #  - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ./hadoop.env
    ports:
      - 50075:50075

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop2.7.4-java8
    container_name: resourcemanager
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075"
    env_file:
      - ./hadoop.env
    ports:
      - 8088:8088
      - 8032:8032

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop2.7.4-java8
    container_name: nodemanager
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 resourcemanager:8088"
    env_file:
      - ./hadoop.env
    depends_on:
      - namenode
      - resourcemanager
    ports:
      - 8042:8042
  hive-server:
    container_name: hive-server
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"
  hive-metastore:
    container_name: hive-metastore
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
  hive-metastore-postgresql:
    container_name: hive-metastore-postgresql
    image: bde2020/hive-metastore-postgresql:2.3.0


  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop2.7.4-java8
    container_name: historyserver
    #volumes:
    #  - hadoop_historyserver:/hadoop/yarn/timeline
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 resourcemanager:8088"
    depends_on:
      - resourcemanager
    env_file:
      - ./hadoop.env
    ports:
      - 8188:8188
      - 19888:19888
  zoo:
    image: zookeeper:3.4.10
    container_name: zookeeper
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=0.0.0.0:2888:3888
      ZOO_TICK_TIME: 15000
    ports:
      - 2181:2181
  spark-master:
    image: bde2020/spark-master:2.4.1-hadoop2.7
    container_name: spark-master
    ports:
      - "8082:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    volumes:
      - $PWD/../shared:/data
  spark-worker-1:
    image: bde2020/spark-worker:2.4.1-hadoop2.7
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
  kafka:
    image: wurstmeister/kafka:2.12-2.2.1
    container_name: kafka
    depends_on:
      - zoo
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zoo:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_ADVERTISED_LISTENERS=INSIDE://kafka:9093,OUTSIDE://localhost:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      - KAFKA_LISTENERS=INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      - KAFKA_INTER_BROKER_LISTENER_NAME=INSIDE
    #volumes:
    #  - $PWD/../shared/kafka:/kafka

  kafka_manager:
    image: hlebalbau/kafka-manager:2.0.0.2
    container_name: kafka_manager
    ports:
      - "9000:9000"
    environment:
      - ZK_HOSTS=zoo:2181
      #- KAFKA_MANAGER_AUTH_ENABLED=true
      #- KAFKA_MANAGER_USERNAME=hai
      #- KAFKA_MANAGER_PASSWORD=hai
    command: -Dpidfile.path=/dev/null

  zeppelin:
    image: apache/zeppelin:0.8.1
    container_name: zeppelin
    ports:
      - "8080:8080"
    volumes:
      - $PWD/../shared/zeppelin/notebook:/zeppelin/notebook/
#volumes:
#  hadoop_namenode:
#  hadoop_datanode:
#  hadoop_historyserver:
